# Meeting 02.12.2022 - Progress

##  Agenda

### AnyBURL Baseline
- AnyBURL unterstützt die Suche nach Regeln, welche ein bestimmtes Triple implizieren leider nicht direkt. 
- Wir haben mit Christian gesprochen und bisher wurde dieses Feature nur zusammen mit der Erstellung der Kandidaten Rankings in AnyBURL umgesetzt. 
- Allerdings hat er unabhängig von AnyBURL ein kleines Tool geschrieben, welches für ein Triple und eine Regel entscheidet ob die Regel das Triple impliziert.
- Wir werden mit ihm telefonieren um die Implementierung genauer zu verstehen + würden ggf. kleine Teile umcoden, um das ganze auf unseren Use Case anwendbar zu machen
- **Frage: Sollen wir dieses Tool als Baseline nutzen mit der selben Regel Filterung und einer Schleife?**

### Umsetzung der Views pro Regel(typ)

Ansatz: Für jeden Regeltyp oder jede Regel eine View zu erstellen um Parstetime zu verringern umgesetzt, performed aber sehr schlecht ( >2.5sek Pro Abfrage)

- uns fällt aber keine Möglichkeit ein das ganze Overhead umzusetzen 
- Laut unserer Tests ist eine direkte Ausführung immer sehr viel effizienter als der Zwischenschritt über Views
Eine Umsetzung als Funktion für jeden Regeltyp, der nur noch die zu prüfenden Paramter (subject/object) übergeben werden und die dann das SQL Statement ausführt, würde unserem Verständnis nach, die Zeit für das Parsen verkürzen + den Zwischenschritt über Views vermeiden
- Zusätzlich: Teilweise für einzelne Regeln (bzw. eher Regeltypen) materialized Views erstellen --> Auswahl durch starke Häufigkeit / lange Berechnungszeiten (z.B Top 25%)



### Experimente

Datenset: YAGO3-10 (+ ggf. Andere?)

- Vergleich mit der Baseline: AnyBURL vs. unsere beste Umsetzung (?)

- Ablations Studie:
  - Beste Umsetzung: 1 Table (Materialized View) pro Relation + beste Indizierungsmethode (Unqiue Clustered Index) + Materialized Views für einzelne Regeln / Regeltypen + Umsetzung als Funktion für geringeren Parse-Aufwand
    - Vergleich verschiedener Indizierungsmethoden (Unique Clustered Index nur auf  Subject, Unique Clustered Index nur auf Obj, Gar keine Indizes)
      -  Wichtig bzgl Indizierung: in beide Richtungen Indizieren: (S,O), (O,S)
    - Vergleich mit / ohne Materialized Views für einzelne Regeln / Regeltypen
    - Vergleich mit / ohne Umsetzung als Funktion für geringeren Parse-Aufwand
  - Vergleich "Beste Umsetzung" vs. Umsetzung mit einem Table für alle Triple des Knowledge Graphen (der Rest bleibt gleich)
    - Insbesondere Vergleich nur für "kurze" Regeln

- Quantil Analyse mit Blick auf die Execution Time für verschiedene Regeltypen (Anzahl der Variablen)
  - Vergleich Beste Umsetzung mit / ohne Materialized Views für einzelne Regeln / Regeltypen um hier die Auswirkung zu sehen
  - Umsetzug der Quantilanalyse: 
    - With Explain Analyze: die theoretische Aufteilung pro Regel ansehen, die sie benötigt
    - Darauf aufbauend, dann die Dauer pro Regel runterbrechen 
  - 1000 Regeln Samplen, die größten Regeltypen analysieren und ggf. hier materialisieren
  - Ziel: Zeigen ob es sich überhaupt lohnt, nicht eine perfekte Lösung zu zeigen.
  - Allgemein Laufzeiten auf Quantile aufteilen 

- Unserer besten Umsetzung angewendet auf verschiedene Datensätze (?)
  - z.B.: Yago3-10 (wenige Relations) vs FB15k-237 (viele Relations), aber nur um zu Zeigen, dass die Umsetzung auch für andere Datensets funktioniert, keine Schlussfolgerung zeigt

- Multithreading inkludieren nicht in den Experimenten (wegen scope), weisen aber am Ende des Papers, neben einer RDF3X Umsetzung als mögliche weitere Performance Verbesserung hin, richtig?

### Paper Draft

- Was wäre ein passender Titel? Sollte man diesen Titel kürzer / anders formulieren?
  - Aktuell: "Comparison of Methods for checking if Facts are implied by Rules based on a fixed Knowledge Graph and Rule Set using a Relational Database"

- Motivation für das Paper:
  - Potenziell Link Prediction / Knowledge Graph Completion (quasi das Selbe) verbessern
  - Grundsätzlich für eine große Menge an Facts schnell überprüfen durch welche Regeln sie impliziert werden
    - Welche Use Cases wären hier denkbar?

[/Paper/Draft_vX.pdf]

### Ergebnisse - Janik

- AnyBURL Vergleich wahrscheinlich verwerfen, bzw. nur mit drei Sätzen und dem Tool von Christian erwähnen
  - Keine Arbeit reinstecken, nicht aufbohren
  - Erwähnen - falls es (hoffentlich!) - deutlich langsamer ist

- Diskussion zu den View
  - Nutzt Prepared Statements
  - Aufpassen, dass es nicht zu viel kostet

- Indexierung in beide Richtungen Unique Clustered Index!

- Materialisierung der Regeln basierend auf der langsamsten Rechendauer
  - Basierend auf Schätzung: EXPLAIN (z.B. nach 1000 Samples aus dem Training Set)
  - Nur Fragen aufwerfen. Keine Lösung präsentieren!
  - Empirische Analyse: "Das hat's gekostet, das hat's gebracht"

- Experimente
  - Für alles Namen verwenden. Ihr sollt leicht auf Dinge referenzieren können im Paper.
  - Experiment kurze vs. lange Regeln aufteilen in Regeln mit einem Body Triple und mit zwei Body Triplen
  - Quantil Analyse
    - Attribution als Herausforderung
    - EXPLAIN als notdürftige Lösung. Es ist nur eine Kostenschätzung

- Mehr Datensätze
  - Eventuell verschiedene Regelmengen für YAGO3-10 (AnyBURL Trainingsdauer)
  - Eventuell andere Datensets mit der besten Lösung

- Titel des Papers
  - "From Facts to Rules in Relational Databases"
  - "Which Rules imply this Fact?"

- Knowledge Graph Completion ist quasi Link Prediction in unserem Kontext
  - Wir verwenden primär den Begriff Link Prediction

- "Rule Guided Embedding Learning" Paper als Beispiel für Kombination

- Unsere Arbeit ist ein Primitiv, welches man braucht um ggf. bessere Lösungen zu entwickeln

- Explainability ist ein Problem in sich, Geschwindigkeit hat keine konkreten Anwendungsbeispiele, außer wenn man "viele Fragen hat"

- Latex Tamplate !!!

- Kein Bla Bla
  - Warum steht dieser Satz in diesem Papier?
  - "In diesem Paper schauen wir uns folgendes Problem an..."

- Überlegt euch: "Wie viele Seiten für was?"

- Die Introduction sollte bereits die Contributions beinhalten

- Preliminaries raus bzw. in das Problem Statement integrieren

- Ein Beispiel durch das Problem Statement zu verwenden

- Implementation
  - Summary kann ein Satz
  - Erst naive Lösung einmal präsentieren und dann Verbesserungsideen aufzeigen

- Schreibt nicht in den Text was in den Tables steht

- Experimente (Paper)
  - Ziele der Experimente / Forschungsfrage / Was will ich herausfinden
  - Was ist das Experimentelle Setup

- Conclusion
  - Ergebnisse ganz knapp! In drei Sätzen.
  - Limitierungen / Next Steps (Multithreading, RDF-3X, ...)
