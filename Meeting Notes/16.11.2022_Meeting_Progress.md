# Meeting 16.11.2022 - Progress

## 1. Bisheriger Fortschritt

### Experimentelle Umsetzung - Datenbankstrukturen:
Bisher experimentell umgesetzt:

- **knowledgegraph**(sub, pre, object) - Mit Covering Clustered Primary Index auf (subject, predicate, object) 
  - In der Datenbank sind Table und Attribute in Abkürzungen geschrieben, um die Query größe zu vermindern
- Für jede existierende Relation wurde eine materialized View v0, v1,...vN mit N = Anzahl existierender Relationen erstellt. Jede View hat die Form v(subject, object) mit Unique Clustering Index auf (subject, object)
  - Für jedes Triple im Body der Regel die validiert werden soll, wird anstatt im Knowledgegraph jetzt in der entsprechenden View die für das Body Tripel passt, gesucht
  - Ansatz ist hier, dass vor allem bei sehr großen Knowledgegraphen und vielen Regeln in einer Query die Suchzeit im B-Tree der Queries zu hoch wird
  - Daher wird der knowledgegraph in kleinere Teile aufgeteilt aufgeteilt
  - **Nachteil:** Vergleiche zwischen Bodys finden dadurch über verschiedene Tables hinweg statt (Hypothese ist daher, dass es nur für große Regelmengen relevant wird)

Andere Ansätze wie Indizes nur auf zwei der 3 Spalten oder gar keine Indizes haben in ersten Tests schlechter abgeschnitten. Hier haben wir aber noch keine vergleichbaren Daten, da wir es noch nicht auf dem Server testen konnten.

### Wie funktioniert eine Query:

- Eine Query hat die Form:
  - (SELECT {RuleID} FROM iku k1, iku k2, ... WHERE k1.pre = ... AND k2.pre = ... AND k1.sub = ... AND ... LIMIT 1) UNION ALL SELECT {RuleID2} FROM ...
    - Statement wurde umgeschrieben in SELECT ... LIMIT 1


### Messungen

- Knowledgegraph: Trainingsset YAGO3 - 1079040 Tripel
- Regelmenge: AnyBURL generierte Regelmenge nach 50s
    - Gefiltert nach simplen Regeln (Da AnyBURL so auch vorgeht):
        1. h(X, Y ) ← r(X, Y )
        2. h(X, Y ) ← r1(X, Z) ∧ r2(Z, Y ) (2)
        3. h(X, e1) ← r(X, e2), (3)
    - Regelmenge von **19271** simplen Regeln
- Query Menge: Validierungsdatenset YAGO3 - 5000 Tripel
- Messung der Gesamtdauer
- Messung der Durchschnittszeit pro Anfrage
- Die Messungen haben wir auf dem Uni Server durchgeführt

NoViews:
Gesamtzeit: 18365 ms
Durchschnittszeit: 3 ms
Abfragen: 5000

Views:
Gesamtzeit: 27384 ms
Durchschnittszeit: 5 ms
Abfragen: 5000


**Durchschnittszeit / Gesamtzeit der Anfragen**
|                |               | Messung      | 
| -------------- | ------------- | ------------ |
| AnyBURL        | Durchschnitt  | 11 ms        |
|                | Gesamt        | 55982 ms     |
| View Umsetzung | Durchschnitt  | 5 ms         | 
|                | Gesamt        | 27384        | 
| Indexed Kg     | Durchschnit   | 3 ms         | 
|                | Gesamt        | 18365 ms     | 

## 2. Next Steps

**1. Optimierung des Vor-Filterns der Regelmenge**
  - Parallel Streaming oder andere effizientere Methoden

**2. Bezüglich der Überprüfung in der Datenbank**
  - Da meistens der Body in unseren Beispielen nicht signifikant groß ist, wurde es so wie jetzt gemacht, aber:
    - ggf. effizienter wenn die Triple des Bodys per INTERSECT zusammengefügt aber jeweils einzeln überpüft werden oder per JOIN zusammengebracht, muss noch getested werden

**3. Testen verschiedener Indizierungsmethoden**
  - **knowledgegraph**(subject, relation, object) mit index (subject, relation, object) & index(relation) & index(relation, object) & index(relation, subject) —> Falls in der Anfrage nicht alle 3 Columns abgefragt werden, könnte diese Umsetzung sinvoll sein

  - **knowledgegraph**(subject, relation, object) mit Primary Key (subject, relation, object) —> Clustered Primary Index, kann theoretisch durch höhere cache hits zu besserer performance führen (Das ist die Annahme)

**4. Vollständige Umsetzung in der Datenbank**
  - Regeln ebenfalls Teil der Datenbank statt Klassenstruktur

# Learnings
- Regeln Partitionieren - DONE
  - Eine Frei, eine gebunden
  - Eine gebunden, eine frei
  - Beide gebunden
  - Beide Frei

- Select Statement umwandeln in - Probiert (muss man testen):
  - SELECT DISTINCT RULE FROM
  - Implementieren der Selects mit Intersects/Join anstatt alles in einem where

- Ideen
  - Jede Regel zur View machen
  - Verschiedene Tables Für verschiedene Indizes


- Einfluss verschiedener Punkte evaluieren:
  - Beste variante nehmen und dann jeweils einen Punkt wegnehmen + evaluieren
    - Queries mit predicates ausgeschrieben
    - Was bringt vorfiltering
    - Was bringen views

  
- YAGO3 nehmen - richtige ANYBURL Regelmenge - 50s / 100s
- Valididierungsdaten rausnehmen, top-k messen
- Mit Describe anschauen, welche Indizes wirklich genutzt werden
- Paper Strukturieren:
  - Motivation, Ziel, Ergebnisse
- Eigenen Server holen
  - Keine GPU benötigt