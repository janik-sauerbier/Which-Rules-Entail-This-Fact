# Meeting 02.12.2022 - Progress

##  Agenda

### AnyBURL Baseline
- AnyBURL unterstützt die Suche nach Regeln, welche ein bestimmtes Triple implizieren leider nicht direkt. 
- Wir haben mit Christian gesprochen und bisher wurde dieses Feature nur zusammen mit der Erstellung der Kandidaten Rankings in AnyBURL umgesetzt. 
- Allerdings hat er unabhängig von AnyBURL ein kleines Tool geschrieben, welches für ein Triple und eine Regel entscheidet ob die Regel das Triple impliziert.
- Wir werden mit ihm telefonieren um die Implementierung genauer zu verstehen + würden ggf. kleine Teile umcoden, um das ganze auf unseren Use Case anwendbar zu machen
- **Frage: Sollen wir dieses Tool als Baseline nutzen mit der selben Regel Filterung und einer Schleife?**

### Umsetzung der Views pro Regel(typ)

Ansatz: Für jeden Regeltyp oder jede Regel eine View zu erstellen um Parstetime zu verringern umgesetzt, performed aber sehr schlecht ( >2.5sek Pro Abfrage)

- uns fällt aber keine Möglichkeit ein das ganze Overhead umzusetzen 
- Laut unserer Tests ist eine direkte Ausführung immer sehr viel effizienter als der Zwischenschritt über Views
Eine Umsetzung als Funktion für jeden Regeltyp, der nur noch die zu prüfenden Paramter (subject/object) übergeben werden und die dann das SQL Statement ausführt, würde unserem Verständnis nach, die Zeit für das Parsen verkürzen + den Zwischenschritt über Views vermeiden
- Zusätzlich: Teilweise für einzelne Regeln (bzw. eher Regeltypen) materialized Views erstellen --> Auswahl durch starke Häufigkeit / lange Berechnungszeiten (z.B Top 25%)



### Experimente

Datenset: YAGO3-10 (+ ggf. Andere?)

- Vergleich mit der Baseline: AnyBURL vs. unsere beste Umsetzung (?)

- Ablations Studie:
  - Beste Umsetzung: 1 Table (Materialized View) pro Relation + beste Indizierungsmethode (Unqiue Clustered Index) + Materialized Views für einzelne Regeln / Regeltypen + Umsetzung als Funktion für geringeren Parse-Aufwand
    - Vergleich verschiedener Indizierungsmethoden (Unique Clustered Index nur auf  Subject, Unique Clustered Index nur auf Obj, Gar keine Indizes)
    - Vergleich mit / ohne Materialized Views für einzelne Regeln / Regeltypen
    - Vergleich mit / ohne Umsetzung als Funktion für geringeren Parse-Aufwand
  - Vergleich "Beste Umsetzung" vs. Umsetzung mit einem Table für alle Triple des Knowledge Graphen (der Rest bleibt gleich)
    - Insbesondere Vergleich nur für "kurze" Regeln

- Quantil Analyse mit Blick auf die Execution Time für verschiedene Regeltypen (Anzahl der Variablen)
  - Vergleich Beste Umsetzung mit / ohne Materialized Views für einzelne Regeln / Regeltypen um hier die Auswirkung zu sehen
  - Umsetzug der Quantilanalyse: 
    - With Explain Analyze: die theoretische Aufteilung pro Regel ansehen, die sie benötigt
    - Darauf aufbauend, dann die Dauer pro Regel runterbrechen 

- Unserer besten Umsetzung angewendet auf verschiedene Datensätze (?)
  - z.B.: Yago3-10 (wenige Relations) vs FB15k-237 (viele Relations), aber nur um zu Zeigen, dass die Umsetzung auch für andere Datensets funktioniert, keine Schlussfolgerung zeigt

- Multithreading inkludieren nicht in den Experimenten (wegen scope), weisen aber am Ende des Papers, neben einer RDF3X Umsetzung als mögliche weitere Performance Verbesserung hin, richtig?

### Paper Draft

- Was wäre ein passender Titel? Sollte man diesen Titel kürzer / anders formulieren?
  - Aktuell: "Comparison of Methods for checking if Facts are implied by Rules based on a fixed Knowledge Graph and Rule Set using a Relational Database"

- Motivation für das Paper:
  - Potenziell Link Prediction / Knowledge Graph Completion (quasi das Selbe) verbessern
  - Grundsätzlich für eine große Menge an Facts schnell überprüfen durch welche Regeln sie impliziert werden
    - Welche Use Cases wären hier denkbar?

[/Paper/Draft_vX.pdf]
